{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBFr9Tmk0xkfS7QUGWTv57",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ianomunga/SiFT/blob/main/Embeddings_for_Track_Reconstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P64N4VV476vF",
        "outputId": "f492b64c-e9c1-4138-f4eb-d8093931c306"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries,\n",
        "#Numpy for matrix-based numerical processing\n",
        "#Pandas for tabular dataset preprocessing\n",
        "#OS for directory operations\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "\n",
        "# keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, Input\n",
        "from keras.utils import plot_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#metrics & model selection from sklearn\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "8GbKJi4Ff57F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LAL/trackml-library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQoHshkUmM0Z",
        "outputId": "33cd7139-8a08-4790-ffaf-78eb62259c20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trackml-library'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Total 222 (delta 0), reused 0 (delta 0), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (222/222), 43.80 KiB | 533.00 KiB/s, done.\n",
            "Resolving deltas: 100% (133/133), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd trackml-library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bMWOyRvv8ub",
        "outputId": "4fc6b645-38da-4ecd-ff8e-220358dec2d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/trackml-library\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKoGdJRBvvgL",
        "outputId": "f551d1c3-8c08-4713-f934-de5ecc301cf9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/trackml-library\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from trackml==3) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from trackml==3) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21.0->trackml==3) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21.0->trackml==3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.21.0->trackml==3) (1.15.0)\n",
            "Building wheels for collected packages: trackml\n",
            "  Building wheel for trackml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trackml: filename=trackml-3-py2.py3-none-any.whl size=13525 sha256=847a10fa4d31b11451ec6c63e0f1da948d363a9020f4f47f91c492a51b619aec\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/ed/27/1d396a8f852fff410fafe7a696bec06bbfb517c37f60138673\n",
            "Successfully built trackml\n",
            "Installing collected packages: trackml\n",
            "Successfully installed trackml-3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show trackml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO2vL3S7xBdN",
        "outputId": "c9a3a80a-ee02-48d0-ea17-7a8dbb8ddccc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: trackml\n",
            "Version: 3\n",
            "Summary: TrackML utility library\n",
            "Home-page: https://github.com/LAL/trackml-library\n",
            "Author: Moritz Kiehn\n",
            "Author-email: msmk@cern.ch\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: numpy, pandas\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline Embeddings with Word2Vec\n",
        "\n",
        "The logic here is to attempt using embedding approaches like word2vec that are most commonly utilized for encoding text tokens into vectors. Even though the event data being iteratively read from the TrackML library is numerical, I'd like to experiment with the resultant embeddings gotten in this way as dense vectors so that I can have a baseline to evaluate the energetic encodings against."
      ],
      "metadata": {
        "id": "yX0xYR4RnkRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import trackml\n",
        "import gensim\n",
        "\n",
        "hits, cells, particles, truth = trackml.dataset.load_event('/content/trackml-library/build/lib/trackml/dataset.py')\n",
        "#having trouble with the exact filepaths in colab, will fix later>>>\n",
        "\n",
        "\n",
        "# Preprocess the event data as you would with text tokens, to get lists of sentences instead\n",
        "sentences = []\n",
        "for i in range(1000):\n",
        "    event = hits[i:i+1000]\n",
        "    event_features = [event['x'], event['y'], event['z'], event['volume_id'], event['layer_id']]\n",
        "    sentences.append(event_features)\n",
        "\n",
        "# Training word2vec on the lists of sentences\n",
        "model = gensim.models.Word2Vec(sentences, size=5, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Iterating over the first 1000 events from the library and converting each one into a dense vector representation\n",
        "embeddings = []\n",
        "for i in range(1000):\n",
        "    event = sentences[i]\n",
        "    event_embedding = [model[feature] for feature in event]\n",
        "    embeddings.append(event_embedding)"
      ],
      "metadata": {
        "id": "ZkR8R53hlLP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Numerical Embeddings using Normalized Vectors' Cosine Similarity Scores\n",
        "\n",
        "This would definitely perform better than ust word2vec, since it caters to the numerical aspects of the event data that would typically be recorded from HEP experiments at CERN, and is exactly what event data from TrackML would need. Here, approaches for embedding energetic tensors from numerical event data through parsing them into vectors of normalized dimensionalities then computing their cosine similarity are defined. This will serve as a preliminary analogue for performing energetic embeddings."
      ],
      "metadata": {
        "id": "YedSxTenwUBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "H1BQyx9zvlqp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __init__(self, d=2, min_bound=0, max_bound=100, norm=\"l2\"):\n",
        "        self.d = d \n",
        "        self.min_bound = min_bound\n",
        "        self.max_bound = max_bound\n",
        "        self.norm = norm  #x and y is constrained to unit length\n",
        "        self.M = np.random.normal(0, 1, (self.d, self.d))\n",
        "        self.Q, self.R = np.linalg.qr(self.M, mode=\"complete\")  # Use QR decomposition for the orthonormal basis, Q\n",
        "    \n",
        "def __linear_mapping(self, num):\n",
        "        norm_diff = num / abs(self.min_bound - self.max_bound)\n",
        "        theta = norm_diff * math.pi\n",
        "        return theta\n",
        "    \n",
        "def make_embedding(self, num):\n",
        "        r = 1\n",
        "        theta = self.__linear_mapping(num)\n",
        "        if self.d == 2:\n",
        "            polar_coord = np.array([r*math.cos(theta), r*math.sin(theta)])\n",
        "        elif self.d > 2:\n",
        "            polar_coord = np.array([math.sin(theta)**(dim-1) * math.cos(theta) if dim < self.d else math.sin(theta)**(self.d) for dim in range(1, self.d+1)])\n",
        "        else:\n",
        "            raise ValueError(\"Wrong value for `d`. `d` should be greater than or equal to 2.\")\n",
        "            \n",
        "        embedding = np.dot(self.Q, polar_coord)  # Numerical embedding for `num`\n",
        "        \n",
        "        return embedding"
      ],
      "metadata": {
        "id": "2D_3TS9NyAqU"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}